from sentence_transformers import SentenceTransformer
from db import getConnection
from openai import OpenAI
import os
from dotenv import load_dotenv
from typhoon_ocr import prepare_ocr_messages
import json
import time

load_dotenv()

conn = getConnection()
cur = conn.cursor()

embedder = SentenceTransformer("BAAI/bge-m3")

client = OpenAI(
    base_url=os.getenv("TYPHOON_BASE_URL"),
    api_key=os.getenv("TYPHOON_API_KEY")
)

def add_documents(documents):
    embeddings = embedder.encode(documents).tolist()
    cur.execute("INSERT INTO documents (content, embedding) VALUES (%s, %s)", (documents, embeddings))
    conn.commit()

def query_documents(query, k=5):
    query_embedding = embedder.encode(query).tolist()
    
    query_embedding_str = "[" + ", ".join(map(str, query_embedding)) + "]"
    
    sql_query = """
        SELECT content, embedding <=> %s::vector AS similarity_score
        FROM documents
        ORDER BY similarity_score ASC
        LIMIT %s;
    """
    
    cur.execute(sql_query, (query_embedding_str, k))
    results = cur.fetchall()
    return results

def generate_response(query_text):
    start = time.time()

    retrievend_docs = query_documents(query_text, 5)
    
    context = "\n".join([doc[0] for doc in retrievend_docs])
    prompt = f"""
    ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:
    {context}

    ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query_text}
    """
    
    response = client.chat.completions.create(
        model=os.getenv("TYPHOON_MODEL"),
        messages=[
            {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏∑‡πà‡∏≠ Typhoon ‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÅ‡∏Å‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢"},
            {"role": "user", "content": prompt}
        ],
        max_tokens=512,
        temperature=0.6,
        top_p=0.95,
    )

    end = time.time()
    print(f"Time taken: {end - start:.2f} seconds")

    return response.choices[0].message.content

# print(response.choices[0].message.content)
# print(generate_response("‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£"))

def process_document(pdf_or_image_path, task_type="default", page_number=1):
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PDF ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ Typhoon OCR
    
    Args:
        pdf_or_image_path (str): path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå PDF ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        task_type (str): "default" ‡∏´‡∏£‡∏∑‡∏≠ "structure"
        page_number (int): ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PDF (default: 1)
    
    Returns:
        str: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å OCR
    """
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if not os.path.exists(pdf_or_image_path):
        return f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {pdf_or_image_path}"
    
    try:
        print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {pdf_or_image_path}")
        print(f"üìÑ ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà: {page_number}")
        print(f"üéØ ‡πÇ‡∏´‡∏°‡∏î: {task_type}")
        print("-" * 50)
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° OCR messages
        messages = prepare_ocr_messages(
            pdf_or_image_path=pdf_or_image_path,
            task_type=task_type,
            target_image_dim=1800,
            target_text_length=8000,
            page_num=page_number
        )
        
        print("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á API...")
        
        # ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á Typhoon OCR API
        response = client.chat.completions.create(
            model=os.getenv("TYPHOON_OCR_MODEL"),
            messages=messages,
            max_tokens=16384,
            extra_body={
                "repetition_penalty": 1.2,
                "temperature": 0.1,
                "top_p": 0.6,
            },
        )
        
        text_output = response.choices[0].message.content
        
        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏á JSON ‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á natural_text
        try:
            json_data = json.loads(text_output)
            markdown_result = json_data.get('natural_text', "").replace("<figure>", "").replace("</figure>", "")
        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á JSON ‡πÑ‡∏î‡πâ: {str(e)}")
            print("üìù ‡πÉ‡∏ä‡πâ output ‡∏î‡∏¥‡∏ö‡πÅ‡∏ó‡∏ô...")
            markdown_result = text_output
        
        return markdown_result
    
    except Exception as e:
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"